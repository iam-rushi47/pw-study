{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYnpGb+cQaK2r6mXOTfkID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iam-rushi47/pw-study/blob/main/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution to Regression Questions\n",
        "\n",
        "---\n",
        "\n",
        "### 1. What is Simple Linear Regression\n",
        "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable **Y** and a single independent variable **X** using a linear equation of the form:\n",
        "\n",
        "\\[\n",
        "Y = mX + c\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### 2. What are the key assumptions of Simple Linear Regression\n",
        "1. **Linearity**: The relationship between X and Y is linear.\n",
        "2. **Independence**: Observations are independent of each other.\n",
        "3. **Homoscedasticity**: Constant variance of errors.\n",
        "4. **Normality of Errors**: Residuals should be normally distributed.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. What does the coefficient _m_ represent in the equation Y = mX + c\n",
        "- _m_ represents the **slope**, which indicates the change in Y for a one-unit increase in X.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. What does the intercept _c_ represent in the equation Y = mX + c\n",
        "- _c_ is the **Y-intercept**, which is the predicted value of Y when X = 0.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. How do we calculate the slope _m_ in Simple Linear Regression\n",
        "\n",
        "\\[\n",
        "m = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### 6. What is the purpose of the least squares method in Simple Linear Regression\n",
        "- To minimize the **sum of squared residuals** (errors), thereby finding the best-fitting line.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression\n",
        "- **R²** indicates the proportion of variance in the dependent variable explained by the independent variable.\n",
        "- Value ranges from **0 to 1**, where 1 means perfect fit.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. What is Multiple Linear Regression\n",
        "- A regression technique where a dependent variable Y is predicted using **two or more** independent variables.\n",
        "\n",
        "\\[\n",
        "Y = b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### 9. What is the main difference between Simple and Multiple Linear Regression\n",
        "- **Simple Linear Regression**: One independent variable.\n",
        "- **Multiple Linear Regression**: Two or more independent variables.\n",
        "\n",
        "---\n",
        "\n",
        "### 10. What are the key assumptions of Multiple Linear Regression\n",
        "1. **Linearity** of relationships.\n",
        "2. **Multivariate Normality** of residuals.\n",
        "3. **No Multicollinearity** among independent variables.\n",
        "4. **Homoscedasticity**.\n",
        "5. **Independence** of residuals.\n",
        "\n",
        "---\n",
        "\n",
        "### 11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model\n",
        "- **Heteroscedasticity** occurs when the variance of residuals is not constant.\n",
        "- It leads to **inefficient estimates** and affects **confidence intervals and hypothesis tests**.\n",
        "\n",
        "---\n",
        "\n",
        "### 12. How can you improve a Multiple Linear Regression model with high multicollinearity\n",
        "1. Remove or combine correlated predictors.\n",
        "2. Use **Principal Component Analysis (PCA)**.\n",
        "3. Use **Regularization techniques** (e.g., Ridge, Lasso).\n",
        "\n",
        "---\n",
        "\n",
        "### 13. What are some common techniques for transforming categorical variables for use in regression model\n",
        "- **One-Hot Encoding**\n",
        "- **Label Encoding**\n",
        "- **Ordinal Encoding** (for ordered categories)\n",
        "- **Binary Encoding**\n",
        "\n",
        "---\n",
        "\n",
        "### 14. What is the role of interaction terms in Multiple Linear Regression\n",
        "- Interaction terms capture the **combined effect** of two or more variables on the dependent variable.\n",
        "\n",
        "Example:\n",
        "\n",
        "\\[\n",
        "Y = b_0 + b_1X_1 + b_2X_2 + b_3(X_1 \\cdot X_2)\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### 15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression\n",
        "- In **Simple Linear Regression**, the intercept is the value of Y when X = 0.\n",
        "- In **Multiple Linear Regression**, it is the value of Y when **all independent variables are 0**, which may or may not have practical meaning.\n",
        "\n",
        "---\n",
        "\n",
        "### 16. What is the significance of the slope in regression analysis, and how does it affect predictions\n",
        "- The slope indicates the **rate of change** in the dependent variable for a one-unit increase in the independent variable.\n",
        "- It directly affects the **magnitude and direction** of predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### 17. How does the intercept in a regression model provide context for the relationship between variables\n",
        "\n",
        "- The intercept sets the **baseline level** of the dependent variable.\n",
        "- It allows us to interpret the starting point when all predictors are zero.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SUZqmT0bEtlx"
      }
    }
  ]
}